{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "442aec37",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Maybe you meant '==' or ':=' instead of '='? (2605793822.py, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 11\u001b[1;36m\u001b[0m\n\u001b[1;33m    df = (pd.read_csv(path),encoding='cp1252')\u001b[0m\n\u001b[1;37m                            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax. Maybe you meant '==' or ':=' instead of '='?\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def data_frame_cleaning:\n",
    "    df_2 = df2.dropna(how='all', axis=0)\n",
    "    df_3= df_2.drop_duplicates(subset = [\"Case Number.1\", \"Case Number.2\"], inplace=False, keep=\"last\")\n",
    "    df_4= df_3.drop_duplicates(subset = [\"href formula\", \"href\"], inplace=False, keep=\"first\")\n",
    "    return df\n",
    "\n",
    "def Years_cleaning:\n",
    "    df4 = df_4.dropna(subset=[\"Year\"])\n",
    "    df5 = df4.dropna(subset=[\"Date\"])\n",
    "    df5['New_Year'] = df5['Date'] # create a new column with the same values as the original \"Year\" column\n",
    "    df5[\"All_years\"] = df5[\"New_Year\"].str.extract(\"(\\d{4})\")\n",
    "    df6 = df5.dropna(subset=[\"All_years\"])\n",
    "    df6['Year'] = df6['Year'].astype(int)\n",
    "    df6['All_years'] = df6['All_years'].astype(int)\n",
    "    df6.loc[df4['Year'] < 1542, 'Year'] = df6.loc[df4['Year'] < 1542, 'All_years']\n",
    "    return df\n",
    "\n",
    "def Country_cleaning:\n",
    "    df6.loc[df6['Country'].isnull(), 'Country'] = df6['Area'] \n",
    "    n_nulls = df6['Country'].isnull().sum()\n",
    "    df6.loc[df6['Country'].isnull(), 'Country'] = df6['Location']\n",
    "    df7 = df6.dropna(subset=[\"Country\"])\n",
    "    df7['Country'] = df7['Country'].str.upper()\n",
    "    df7.insert(5, \"Oceans\", \"\")\n",
    "    for index, row in df7.iterrows():\n",
    "    if row['Country'] in north_atlantic:\n",
    "        df7.at[index, 'Oceans'] = 'North_Atlantic'\n",
    "    for index, row in df7.iterrows():\n",
    "    if row['Country'] in south_atlantic:\n",
    "        df7.at[index, 'Oceans'] = 'South_Atlantic'\n",
    "    for index, row in df7.iterrows():\n",
    "    if row['Country'] in north_pacific:\n",
    "        df7.at[index, 'Oceans'] = 'North_Pacific'\n",
    "    for index, row in df7.iterrows():\n",
    "    if row['Country'] in south_pacific:\n",
    "        df7.at[index, 'Oceans'] = 'South_pacific'\n",
    "    for index, row in df7.iterrows():\n",
    "    if row['Country'] in mediterranean_sea:\n",
    "        df7.at[index, 'Oceans'] = 'Mediterranean_Sea'\n",
    "    for index, row in df7.iterrows():\n",
    "    if row['Country'] in caribbean_sea:\n",
    "        df7.at[index, 'Oceans'] = 'Caribbean_Sea'\n",
    "    for index, row in df7.iterrows():\n",
    "    if row['Country'] in Bay_bengal_andaman_sea:\n",
    "        df7.at[index, 'Oceans'] = 'Bay_bengal_andaman_sea'\n",
    "    for index, row in df7.iterrows():\n",
    "    if row['Country'] in red_sea:\n",
    "        df7.at[index, 'Oceans'] = 'Red_Sea'\n",
    "    for index, row in df7.iterrows():\n",
    "    if row['Country'] in indian_ocean:\n",
    "        df7.at[index, 'Oceans'] = 'Indian_Ocean'\n",
    "    for index, row in df7.iterrows():\n",
    "    if row['Country'] in south_china_sea:\n",
    "        df7.at[index, 'Oceans'] = 'South_China_Sea'\n",
    "    for index, row in df7.iterrows():\n",
    "    if row['Country'] in persian_golf:\n",
    "        df7.at[index, 'Oceans'] = 'persian_golf'\n",
    "    for index, row in df7.iterrows():\n",
    "    if row['Country'] in adriatic_sea:\n",
    "        df.at[index, 'Oceans'] = 'Adriatic_Sea'\n",
    "    ocean_rows = df7['Country'].str.contains('OCEAN')\n",
    "    ocean_names = df.loc[ocean_rows, 'Country'].str.extract(r'(\\w+\\sOCEAN)')\n",
    "    df.loc[ocean_rows, 'Oceans'] = ocean_names.values\n",
    "    df['Oceans'] = df['Oceans'].replace(ocean_dict)\n",
    "    no_ocean_applied=df['Oceans']==\"\"\n",
    "    df=df.drop(df8[no_ocean_applied].index)\n",
    "    return df\n",
    "\n",
    "def time_cleaning:\n",
    "    df9 = df8.dropna(subset=[\"Time\"])\n",
    "    df9['Cleaned_Time'] = df9['Time'].str.extract(r'^(\\d+)h')\n",
    "    df9.loc[df9['Cleaned_Time'].str.contains(r'^\\d{2}$') & df9['Cleaned_Time'].notnull(), 'Time'] = df9['Cleaned_Time']\n",
    "    subset = df9.loc[:, ['Time', 'Cleaned_Time']]\n",
    "    df9['time frame'] = df9['Time'].str.extract(r'([a-zA-Z]{2,})').fillna('') #matches any sequence of 2 or more consecutive letters\n",
    "    def set_time_frame(time):\n",
    "        time = int(time)\n",
    "        if 6 <= time <= 9:\n",
    "            return 'Sunrise'\n",
    "        elif 10 <= time <= 13:\n",
    "            return 'Morning'\n",
    "        elif 14 <= time <= 18:\n",
    "            return 'Afternoon'\n",
    "        else:\n",
    "            return 'Night'\n",
    "    df9['Cleaned_Time'] = df9['Cleaned_Time'].fillna(0).astype(int)\n",
    "    df9['Time frame'] = df9['Cleaned_Time'].apply(set_time_frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8427d04c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
